{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "#from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 127) (5000, 127)\n"
     ]
    }
   ],
   "source": [
    "roo = './roo1.csv'\n",
    "df  = pd.read_csv(roo)\n",
    "\n",
    "data      = df.copy()\n",
    "train_set = data.sample(frac=0.75)\n",
    "test_set  = data.drop(train_set.index)\n",
    "\n",
    "# print ('Training set')\n",
    "# print (train_set.head())\n",
    "# print ('\\nTest set')\n",
    "# print (test_set.head())\n",
    "# print ('\\nOriginal DataFrame')\n",
    "# print (data.head())\n",
    "\n",
    "print(train_set.shape,test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.iloc[:,:93]\n",
    "Y_train = train_set.iloc[:,93:]\n",
    "\n",
    "X_test  = test_set.iloc[:,:93]\n",
    "Y_test  = test_set.iloc[:,93:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set shape            : (15000, 127)\n",
      "test_set shape             : (5000, 127)\n",
      "Number of training examples: 15000\n",
      "Number of testing examples : 15000\n",
      "\n",
      "********************************************\n",
      "\n",
      "X_train shape: (15000, 93)\n",
      "Y_train shape: (15000, 34)\n",
      "X_test shape: (5000, 93)\n",
      "Y_test shape: (5000, 34)\n"
     ]
    }
   ],
   "source": [
    "# Explore your dataset \n",
    "m_train = X_train.shape[0] #no of train samples\n",
    "n       = X_train.shape[1] #no of train features\n",
    "m_test  = Y_train.shape[0] #no of test samples\n",
    "\n",
    "print (\"train_set shape            : \" + str(train_set.shape))\n",
    "print (\"test_set shape             : \" + str(test_set.shape))\n",
    "print (\"Number of training examples: \" + str(m_train))\n",
    "print (\"Number of testing examples : \" + str(m_test))\n",
    "print (\"\\n********************************************\\n\")\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "#print(Y_test.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(0, 15000)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0, 15000)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-2099a2153ca1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#     X_test.iloc[:,i] = (X_test.iloc[:,i] - myu[i])/sig[i]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#16528                                  0.051329\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0, 15000)"
     ]
    }
   ],
   "source": [
    "# Normalising the marks columns (1-9)\n",
    "myu = [77.01333333333334, 76.96693333333333, 77.03626666666666, 77.10393333333333, 76.9222,          77.0074,           77.04806666666667, 76.92826666666667, 76.9128]\n",
    "sig = [77.66900969284124, 77.62744188322410, 77.70232772146105, 77.76290075179381, 77.5714290186793, 77.67784282964266, 77.70757963888293, 77.59615883964017, 77.57365790008875]\n",
    "#array contains variance of all train columns\n",
    "\n",
    "# for i in range(9):\n",
    "#     X_train.iloc[:,i] = (X_train.iloc[:,i] - myu[i])/sig[i]\n",
    "#     X_test.iloc[:,i] = (X_test.iloc[:,i] - myu[i])/sig[i]\n",
    "    \n",
    "print(X_train[0,15000])   #16528                                  0.051329"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: create_placeholders\n",
    "#print(X_train.head())\n",
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, no of features (93)\n",
    "    n_y -- scalar, number of classes (34)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    \n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    X = tf.placeholder(dtype = \"float32\" , shape = (n_x,None) , name=\"X\")\n",
    "    Y = tf.placeholder(dtype = \"float32\" , shape = (n_y,None) , name=\"Y\")\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"X:0\", shape=(12288, ?), dtype=float32)\n",
      "Y = Tensor(\"Y:0\", shape=(6, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Tesing\n",
    "X, Y = create_placeholders(12288, 6)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_parameters\n",
    "\n",
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [50, 93]\n",
    "                        b1 : [50, 1]\n",
    "                        W2 : [45, 50]\n",
    "                        b2 : [45, 1]\n",
    "                        W3 : [40, 45]\n",
    "                        b3 : [40, 1]\n",
    "                        W4 : [38, 40]\n",
    "                        b4 : [38, 1]\n",
    "                        W5 : [36, 38]\n",
    "                        b5 : [36, 1]\n",
    "                        W6 : [34, 36]\n",
    "                        b6 : [34, 1]\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 6 lines of code)\n",
    "    W1 = tf.get_variable(\"W1\", [100, 93], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W4 = tf.get_variable(\"W4\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b4 = tf.get_variable(\"b4\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W5 = tf.get_variable(\"W5\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b5 = tf.get_variable(\"b5\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W6 = tf.get_variable(\"W6\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b6 = tf.get_variable(\"b6\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W7 = tf.get_variable(\"W7\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b7 = tf.get_variable(\"b7\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W8 = tf.get_variable(\"W8\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b8 = tf.get_variable(\"b8\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W9 = tf.get_variable(\"W9\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b9 = tf.get_variable(\"b9\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W10 = tf.get_variable(\"W10\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b10 = tf.get_variable(\"b10\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W11 = tf.get_variable(\"W11\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b11 = tf.get_variable(\"b11\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W12 = tf.get_variable(\"W12\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b12 = tf.get_variable(\"b12\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W13 = tf.get_variable(\"W13\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b13 = tf.get_variable(\"b13\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W14 = tf.get_variable(\"W14\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b14 = tf.get_variable(\"b14\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W15 = tf.get_variable(\"W15\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b15 = tf.get_variable(\"b15\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W16 = tf.get_variable(\"W16\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b16 = tf.get_variable(\"b16\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W17 = tf.get_variable(\"W17\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b17 = tf.get_variable(\"b17\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W18 = tf.get_variable(\"W18\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b18 = tf.get_variable(\"b18\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W19 = tf.get_variable(\"W19\", [100, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b19 = tf.get_variable(\"b19\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W20 = tf.get_variable(\"W20\", [34, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b20 = tf.get_variable(\"b20\", [34, 1], initializer = tf.zeros_initializer())\n",
    "#     W21 = tf.get_variable(\"W21\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b21 = tf.get_variable(\"b21\", [40, 1], initializer = tf.zeros_initializer())\n",
    "#     W22 = tf.get_variable(\"W22\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b22 = tf.get_variable(\"b22\", [40, 1], initializer = tf.zeros_initializer())\n",
    "#     W23 = tf.get_variable(\"W23\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b23 = tf.get_variable(\"b23\", [40, 1], initializer = tf.zeros_initializer())\n",
    "#     W24 = tf.get_variable(\"W24\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b24 = tf.get_variable(\"b24\", [40, 1], initializer = tf.zeros_initializer())\n",
    "#     W25 = tf.get_variable(\"W25\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b25 = tf.get_variable(\"b25\", [40, 1], initializer = tf.zeros_initializer())\n",
    "#     W26 = tf.get_variable(\"W26\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b26 = tf.get_variable(\"b26\", [40, 1], initializer = tf.zeros_initializer())\n",
    "#     W27 = tf.get_variable(\"W27\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b27 = tf.get_variable(\"b27\", [40, 1], initializer = tf.zeros_initializer())\n",
    "#     W28 = tf.get_variable(\"W28\", [40, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b28 = tf.get_variable(\"b28\", [40, 1], initializer = tf.zeros_initializer())\n",
    "#     W29 = tf.get_variable(\"W29\", [38, 40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b29 = tf.get_variable(\"b29\", [38, 1], initializer = tf.zeros_initializer())\n",
    "#     W30 = tf.get_variable(\"W30\", [36, 38], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b30 = tf.get_variable(\"b30\", [36, 1], initializer = tf.zeros_initializer())\n",
    "#     W31 = tf.get_variable(\"W31\", [34, 36], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b31 = tf.get_variable(\"b31\", [34, 1], initializer = tf.zeros_initializer())\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\"b1\": b1,\"W2\": W2,\"b2\": b2,\"W3\": W3,\"b3\": b3,\"W4\": W4,\"b4\": b4,\n",
    "                  \"W5\": W5,\"b5\": b5,\"W6\": W6,\"b6\": b6,\"W7\": W7,\"b7\": b7,\"W8\": W8,\"b8\": b8,\n",
    "                  \"W9\": W9,\"b9\": b9,\"W10\": W10,\"b10\": b10,\"W11\": W11,\"b11\": b11,\"W12\": W12,\"b12\": b12,\n",
    "                  \"W13\":W13,\"b13\":b13,\"W14\": W14,\"b14\": b14,\"W15\": W15,\"b15\": b15,\"W16\": W16,\"b16\": b16,\n",
    "                  \"W17\":W17,\"b17\":b17,\"W18\": W18,\"b18\": b18,\"W19\": W19,\"b19\": b19,\"W20\": W20,\"b20\": b20,\n",
    "#                   \"W21\":W21,\"b21\":b21,\"W22\":W22,\"b22\":b22,\"W23\":W23,\"b23\":b23,\"W24\":W24,\"b24\":b24,\n",
    "#                   \"W25\":W25,\"b25\":b25,\"W26\":W26,\"b26\":b26,\"W27\":W27,\"b27\":b27,\"W28\":W28,\"b28\":b28,\n",
    "#                   \"W29\":W29,\"b29\":b29,\"W30\":W30,\"b30\":b30,\"W31\":W31,\"b31\":b31\n",
    "#                  \n",
    "                 }\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/sayali/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "W19 = <tf.Variable 'W19:0' shape=(100, 100) dtype=float32_ref>\n",
      "b19 = <tf.Variable 'b19:0' shape=(100, 1) dtype=float32_ref>\n",
      "W20 = <tf.Variable 'W20:0' shape=(34, 100) dtype=float32_ref>\n",
      "b20 = <tf.Variable 'b20:0' shape=(34, 1) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters()\n",
    "    print(\"W19 = \" + str(parameters[\"W19\"]))\n",
    "    print(\"b19 = \" + str(parameters[\"b19\"]))\n",
    "    print(\"W20 = \" + str(parameters[\"W20\"]))\n",
    "    print(\"b20 = \" + str(parameters[\"b20\"]))\n",
    "#     print(\"W3 = \" + str(parameters[\"W3\"]))\n",
    "#     print(\"b3 = \" + str(parameters[\"b3\"]))\n",
    "#     print(\"W4 = \" + str(parameters[\"W4\"]))\n",
    "#     print(\"b4 = \" + str(parameters[\"b4\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    W4 = parameters['W4']\n",
    "    b4 = parameters['b4']\n",
    "    W5 = parameters['W5']\n",
    "    b5 = parameters['b5']\n",
    "    W6 = parameters['W6']\n",
    "    b6 = parameters['b6']\n",
    "    W7 = parameters['W7']\n",
    "    b7 = parameters['b7']\n",
    "    W8 = parameters['W8']\n",
    "    b8 = parameters['b8']\n",
    "    W9 = parameters['W9']\n",
    "    b9 = parameters['b9']\n",
    "    W10 = parameters['W10']\n",
    "    b10 = parameters['b10']\n",
    "    W11 = parameters['W11']\n",
    "    b11 = parameters['b11']\n",
    "    W12 = parameters['W12']\n",
    "    b12 = parameters['b12']\n",
    "    W13 = parameters['W13']\n",
    "    b13 = parameters['b13']\n",
    "    W14 = parameters['W14']\n",
    "    b14 = parameters['b14']\n",
    "    W15 = parameters['W15']\n",
    "    b15 = parameters['b15']\n",
    "    W16 = parameters['W16']\n",
    "    b16 = parameters['b16']\n",
    "    W17 = parameters['W17']\n",
    "    b17 = parameters['b17']\n",
    "    W18 = parameters['W18']\n",
    "    b18 = parameters['b18']\n",
    "    W19 = parameters['W19']\n",
    "    b19 = parameters['b19']\n",
    "    W20 = parameters['W20']\n",
    "    b20 = parameters['b20']\n",
    "#     W21 = parameters['W21']\n",
    "#     b21 = parameters['b21']\n",
    "#     W22 = parameters['W22']\n",
    "#     b22 = parameters['b22']\n",
    "#     W23 = parameters['W23']\n",
    "#     b23 = parameters['b23']\n",
    "#     W24 = parameters['W24']\n",
    "#     b24 = parameters['b24']\n",
    "#     W25 = parameters['W25']\n",
    "#     b25 = parameters['b25']\n",
    "#     W26 = parameters['W26']\n",
    "#     b26 = parameters['b26']\n",
    "#     W27 = parameters['W27']\n",
    "#     b27 = parameters['b27']\n",
    "#     W28 = parameters['W28']\n",
    "#     b28 = parameters['b28']\n",
    "#     W29 = parameters['W29']\n",
    "#     b29 = parameters['b29']\n",
    "#     W30 = parameters['W30']\n",
    "#     b30 = parameters['b30']\n",
    "#     W31 = parameters['W31']\n",
    "#     b31 = parameters['b31']\n",
    "    \n",
    "    \n",
    "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)                        # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1),b2)                       # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2),b3)                       # Z3 = np.dot(W3,a2) + b3\n",
    "    A3 = tf.nn.relu(Z3)                                    # A3 = relu(Z3)\n",
    "    Z4 = tf.add(tf.matmul(W4,A3),b4)                       # Z4 = np.dot(W4,a3) + b4\n",
    "    A4 = tf.nn.relu(Z4)                                    # A4 = relu(Z4)\n",
    "    Z5 = tf.add(tf.matmul(W5,A4),b5)                       # Z5 = np.dot(W5,a4) + b5\n",
    "    A5 = tf.nn.relu(Z5)                                    # A5 = relu(Z5)\n",
    "    Z6 = tf.add(tf.matmul(W6,A5),b6)                       # Z6 = np.dot(W6,a5) + b6\n",
    "    A6 = tf.nn.relu(Z6)                                    # A5 = relu(Z5)\n",
    "    Z7 = tf.add(tf.matmul(W7,A6),b7)                       # Z6 = np.dot(W6,a5) + b6\n",
    "    A7 = tf.nn.relu(Z7)                                    # A5 = relu(Z5)\n",
    "    Z8 = tf.add(tf.matmul(W8,A7),b8)                       # Z6 = np.dot(W6,a5) + b6\n",
    "    A8 = tf.nn.relu(Z8)                                    # A5 = relu(Z5)\n",
    "    Z9 = tf.add(tf.matmul(W9,A8),b9)\n",
    "    A9 = tf.nn.relu(Z9)                                    # A5 = relu(Z5)\n",
    "    Z10 = tf.add(tf.matmul(W10,A9),b10)\n",
    "    A10 = tf.nn.relu(Z10)                                    # A5 = relu(Z5)\n",
    "    Z11 = tf.add(tf.matmul(W11,A10),b11)\n",
    "    A11 = tf.nn.relu(Z11)                                    # A5 = relu(Z5)\n",
    "    Z12 = tf.add(tf.matmul(W12,A11),b12)\n",
    "    A12 = tf.nn.relu(Z12)                                    # A5 = relu(Z5)\n",
    "    Z13 = tf.add(tf.matmul(W13,A12),b13)\n",
    "    A13 = tf.nn.relu(Z13)                                    # A5 = relu(Z5)\n",
    "    Z14 = tf.add(tf.matmul(W14,A13),b14)\n",
    "    A14 = tf.nn.relu(Z14)                                    # A5 = relu(Z5)\n",
    "    Z15 = tf.add(tf.matmul(W15,A14),b15)\n",
    "    A15 = tf.nn.relu(Z15)                                    # A5 = relu(Z5)\n",
    "    Z16 = tf.add(tf.matmul(W16,A15),b16)\n",
    "    A16 = tf.nn.relu(Z16)                                    # A5 = relu(Z5)\n",
    "    Z17 = tf.add(tf.matmul(W17,A16),b17)\n",
    "    A17 = tf.nn.relu(Z17)                                    # A5 = relu(Z5)\n",
    "    Z18 = tf.add(tf.matmul(W18,A17),b18)\n",
    "    A18 = tf.nn.relu(Z18)                                    # A5 = relu(Z5)\n",
    "    Z19 = tf.add(tf.matmul(W19,A18),b19)\n",
    "    A19 = tf.nn.relu(Z19)\n",
    "    Z20 = tf.add(tf.matmul(W20,A19),b20)\n",
    "#     A20 = tf.nn.relu(Z20)                                    # A5 = relu(Z5)\n",
    "#     Z21 = tf.add(tf.matmul(W21,A20),b21)\n",
    "#     A21 = tf.nn.relu(Z21)                                    # A5 = relu(Z5)\n",
    "#     Z22 = tf.add(tf.matmul(W22,A21),b22)\n",
    "#     A22 = tf.nn.relu(Z22)\n",
    "#     Z23 = tf.add(tf.matmul(W23,A22),b23)\n",
    "#     A23 = tf.nn.relu(Z23)                                    # A5 = relu(Z5)\n",
    "#     Z24 = tf.add(tf.matmul(W24,A23),b24)\n",
    "#     A24 = tf.nn.relu(Z24)                                    # A5 = relu(Z5)\n",
    "#     Z25 = tf.add(tf.matmul(W25,A24),b25)\n",
    "#     A25 = tf.nn.relu(Z25)                                    # A5 = relu(Z5)\n",
    "#     Z26 = tf.add(tf.matmul(W26,A25),b26)\n",
    "#     A26 = tf.nn.relu(Z26)                                    # A5 = relu(Z5)\n",
    "#     Z27 = tf.add(tf.matmul(W27,A26),b27)\n",
    "#     A27 = tf.nn.relu(Z27)                                    # A5 = relu(Z5)\n",
    "#     Z28 = tf.add(tf.matmul(W28,A27),b28)\n",
    "#     A28 = tf.nn.relu(Z28)                                    # A5 = relu(Z5)\n",
    "#     Z29 = tf.add(tf.matmul(W29,A28),b29)\n",
    "#     A29 = tf.nn.relu(Z29)                                    # A5 = relu(Z5)\n",
    "#     Z30 = tf.add(tf.matmul(W30,A29),b30)\n",
    "#     A30 = tf.nn.relu(Z30)                                    # A5 = relu(Z5)\n",
    "#     Z31 = tf.add(tf.matmul(W31,A30),b31)\n",
    "#     ### END CODE HERE ###\n",
    "    \n",
    "    return Z20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z12 = Tensor(\"Add_19:0\", shape=(34, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(93, 34)\n",
    "    parameters = initialize_parameters()\n",
    "    Z12 = forward_propagation(X, parameters)\n",
    "    print(\"Z12 = \" + str(Z12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_cost \n",
    "\n",
    "def compute_cost(Z31, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z4 -- output of forward propagation (output of the last LINEAR unit), of shape (34, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z4\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z31)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)...\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-ff98a105d657>:20: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "cost = Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(93, 34)\n",
    "    parameters = initialize_parameters()\n",
    "    Z31 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z31, Y)\n",
    "    print(\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: random_mini_batches\n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 512, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n",
    "    mini_batch_size -- size of the mini-batches, integer\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    k = 0\n",
    "        \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X.iloc[:, permutation]\n",
    "    shuffled_Y = Y.iloc[:, permutation]\n",
    "#.reshape((1,m))\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = shuffled_X.iloc[:, k*mini_batch_size : (k+1) * mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y.iloc[:, k*mini_batch_size : (k+1) * mini_batch_size]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = shuffled_X.iloc[:, (k+1)*mini_batch_size :  ]\n",
    "        mini_batch_Y = shuffled_Y.iloc[:, (k+1)*mini_batch_size :  ]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 15000)\n",
      "(34, 15000)\n"
     ]
    }
   ],
   "source": [
    "# X_train = X_train.T\n",
    "# Y_train = Y_train.T\n",
    "# X_test  = X_test.T\n",
    "# Y_test  = Y_test.T\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0005,\n",
    "          num_epochs = 1500, minibatch_size = 512, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a four-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 93, number of training examples = 16129)\n",
    "    Y_train -- test set, of shape (output size = 34, number of training examples = 16129)\n",
    "    X_test -- training set, of shape (input size = 93, number of training examples = 3871)\n",
    "    Y_test -- test set, of shape (output size = 34, number of test examples = 3871)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(0)                             # to keep consistent results\n",
    "    seed = 2                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = tf.placeholder(dtype = \"float32\", shape=(n_x, None) , name=\"X\"), tf.placeholder(dtype = \"float32\", shape=(n_y,None) , name=\"Y\")\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    #print(\"here \",X.shape)\n",
    "    Z20 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z20, Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z20), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    \n",
    "        print (\"Train Accuracy : \", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy  : \", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        print (\"Learning_rate  : \",learning_rate)\n",
    "        print (\"Batch Size     : \",minibatch_size)\n",
    "        \n",
    "        confusion = tf.confusion_matrix(labels=Y, predictions=Z20, num_classes=n_y)\n",
    "        print(confusion)\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 15000)\n",
      "Cost after epoch 0: 3.645771\n",
      "Cost after epoch 100: 2.093251\n",
      "Cost after epoch 200: 1.328402\n",
      "Cost after epoch 300: 1.208680\n",
      "Cost after epoch 400: 1.170045\n",
      "Cost after epoch 500: 1.018177\n",
      "Cost after epoch 600: 0.989180\n",
      "Cost after epoch 700: 0.991573\n",
      "Cost after epoch 800: 0.881309\n",
      "Cost after epoch 900: 1.714666\n",
      "Cost after epoch 1000: 0.853395\n",
      "Cost after epoch 1100: 0.770272\n",
      "Cost after epoch 1200: 0.853672\n",
      "Cost after epoch 1300: 0.738545\n",
      "Cost after epoch 1400: 0.855531\n",
      "Cost after epoch 1500: 0.768827\n",
      "Cost after epoch 1600: 0.734353\n",
      "Cost after epoch 1700: 0.550863\n",
      "Cost after epoch 1800: 0.717715\n",
      "Cost after epoch 1900: 0.676261\n",
      "Cost after epoch 2000: 0.498464\n",
      "Cost after epoch 2100: 0.625530\n",
      "Cost after epoch 2200: 0.486129\n",
      "Cost after epoch 2300: 0.404006\n",
      "Cost after epoch 2400: 0.509556\n",
      "Cost after epoch 2500: 0.499192\n",
      "Cost after epoch 2600: 0.465931\n",
      "Cost after epoch 2700: 0.319643\n",
      "Cost after epoch 2800: 0.268148\n",
      "Cost after epoch 2900: 0.389267\n",
      "Cost after epoch 3000: 0.285625\n",
      "Cost after epoch 3100: 0.322142\n",
      "Cost after epoch 3200: 0.277517\n",
      "Cost after epoch 3300: 0.341213\n",
      "Cost after epoch 3400: 0.303806\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy :  0.93413335\n",
      "Test Accuracy  :  0.026\n",
      "Learning_rate  :  0.0005\n",
      "Batch Size     :  512\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "parameters = model(X_train, Y_train, X_test, Y_test,num_epochs = 3500)\n",
    "#24,20,2.14"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
